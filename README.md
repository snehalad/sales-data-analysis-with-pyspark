# ğŸ›ï¸ Sales Data Analysis using PySpark

### ğŸ“ Dataset Summary

  The dataset contains structured transactional data with the following columns:

- Region, Country

- Item Type, Sales Channel

- Order Priority, Order Date, Ship Date

- Units Sold, Unit Price, Unit Cost

- Total Revenue, Total Cost, Total Profit


### ğŸ›£ï¸ Project Workflow
#### 1. ğŸ“ Data Collection & Understanding
  - Loaded sales data from CSV using PySpark.
  
  - Explored schema and data types for initial inspection.
  
  - Understood business context from fields like Region, Sales Channel, Order Priority, etc.

#### 2. ğŸ§¹ Data Cleaning & Preprocessing
- Converted Order Date and Ship Date to Spark DateType.

- Profit Margin = Total Profit / Total Revenue

- Handled missing values and standardized data types.

#### 3. ğŸ“Š Business Analysis & Insights

Performed various group-wise and time-based aggregations using PySpark DataFrame API and SQL:

- ğŸ” Top 5 profitable products by region

- ğŸ’° Online vs. Offline revenue and profit comparison

- ğŸ“¦ Average shipping delay per country

- ğŸ“ˆ Monthly revenue and profit trend

- ğŸšš Effect of order priority on shipping time

- ğŸ“‰ High-selling, low-profit margin products
